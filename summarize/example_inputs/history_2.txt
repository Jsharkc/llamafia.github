================================================================================
chat_session_len:7
用户2:在 repoqa 上浅测了一下最近的新模型 “御三家”居然打平了 [破涕为笑]
用户2:https://evalplus.github.io/repoqa.html
用户1:看到一个基于llama3的sota开源模型smaug，把我们的ExPO方法用在上面做了增强，欢迎大家试用：
https://huggingface.co/chujiezheng/Smaug-Llama-3-70B-Instruct-ExPO
用户1:目前还没卡整评测，希望有富哥来帮测测[让我看看]
用户1:上面这个是70b的模型。还有另一个llama3-8b的增强模型，是基于@熊伟 UIUC/Google alignment agent @Haoxiang Wang-UIUC-RLHF 之前做的，这个测了下有提升，也欢迎大家试用：
https://huggingface.co/chujiezheng/LLaMA3-iterative-DPO-final-ExPO
用户3:https://arxiv.org/abs/2405.10938
用户4:FYI: https://skywritingspress.ca

================================================================================
chat_session_len:68
用户19:@黄文灏-baai-llm 牛逼的
用户28:感谢群主。老实说，分数有点超预期了，不过模型能力在这个范围和我们自己的评测还比较接近。这个版本还比较粗糙，看看之后能不能再迭代一版。
用户21:欢迎大家来交流体验 yi large preview （更欢迎随时反馈badcase[害羞]）
用户3:Yifia和Qwenia哪个先到[旺柴]
用户21:目前只有api [撇嘴]
用户6:[强][强][强]
用户26:那就只有蹲一版技术报告了。
用户5:https://arxiv.org/abs/2405.11143 做了点微不足道的活，被大佬们带了[旺柴]（欢迎大家多提提建议和意见）。此外， 也欢迎大家多关注：https://github.com/OpenLLMAI/OpenRLHF，为开源社区做做共享。
用户15:OpenRLHF 真的好用[ThumbsUp]
尤其是基于Ray的PPO
用户5:[社会社会]
用户5:前两位大佬做了比较多的贡献
用户15:想问一下是开源社区自发组织起来的吗？
因为看到作者来自于3 个不同的公司
用户15:而且我们发现 OpenRLHF ppo 训练的稳定性比其他框架好很多
是因为参考了这些 ppo 的问题性 trick 吗？
https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/
用户15:TRLX 和 deepspeed-chat
用户17:我试过TRL的PPO，确实有问题，主要还是一些设置问题
用户15:或者换种说法, openRLHF 是 off-the-shelf 框架里面最稳定的，集成了很多稳定性 trick，开箱即用
用户6:@初七-NVIDIA-LLM [旺柴]
用户15:[强]久仰
用户14:Copilot 🤝 Minecraft
Your everyday AI companion.
https://x.com/MSFTCopilot/status/1792625882634281231
用户14:powered by OpenAI’s GPT-4o，低延迟、高交互性的优势很明显
还得是 GPT-4o，这体验很丝滑啊
用户25:这种会不会太费tokens
用户14:感觉应该比前几天 GPT-4o 发布会的那个耗费 tokens 好一些。
那个视频处理，是要逐帧转化成图片的 tokens 的，比较费 tokens。

但在 MC 里的视频处理是个可选项，可以从 game core 里提取很多结构化信息。
用户22:我在GAU上的实验结果是alibi和nope的外推能力为0
用户22:比rope还差
用户17:迟一些，我总结一下。
用户24:https://arxiv.org/abs/2401.16421，我们最近做了这个(ICML 2024）感兴趣的同学也可以看看
用户2:@沈炜-南京大学- hulu 谢谢，给你点关注发言了
用户27:打个广告：我们将在icml2024办一个long context foundation models (LCFM)的workshop，欢迎各位大佬投稿/来玩。投稿截止是5.31aoe，详见https://longcontextfm.github.io
用户27:感觉本群对long-context感兴趣的密度极高[奸笑]
用户23:非常感兴趣 多模态最重要的基建能力之一[旺柴]
用户3:[旺柴]
用户10:到时候关注一下 long-context 挺有意思的
用户17:deepspeed stage 3 有没有同学使用这个在8卡上微调过deepseek code 33B 效果好像比 deepspeed stage 2差了好多，😂
用户7:效果指的是？
用户7:训练速度嘛
用户7:那个肯定慢很多了
用户17:我说最终的模型测试效果
用户17:不是速度
用户7:没做过对比，但这不应该有很大的区别吧[破涕为笑]
用户10:不应该升级下版本看看
用户17:哦哦哦，我再准确测试一下
用户19:什么是 in context learning
用户26:以前也没有人分啥cot/ ICL, 就是提示学习。后来给细分了
用户19:4o 还可以
用户12:测了其他几个，表现会有断层下降
用户3:这跟tokenize关系极大😂
用户3:训练tokenizer的数据选的subset不同分词都会有差异吧，还要考虑人工调整的部分[发抖]
用户3:https://x.com/shinboson/status/1792420144511431099?s=46 今天看这个帖子讨论怎么提升算术性能，分词对算术影响还是非常大的，调整格式避免错误分词能提升很多性能
用户8:分词的影响我记得之前有一篇论文已经讨论过：https://arxiv.org/abs/2305.14201
用户9:是不是可以用Experience Replay的方法，训练模型
用户19:好奇有没有什么地方考虑让模型今年同步参加高考 🤔
用户19:以现在的模型能力，参加高考应该没有任何技术上做不了的地方了吧
用户1:高考题目实时给模型公司有安全性问题吧
用户19:考完的那一瞬间给是可以的吧
用户1:应该没问题
用户20:记得以前很多年都有AI参加高考的新闻
用户4:考完的瞬间是可以的 不过高考打分还有蛮多主观的因素在，比如作为河北考生就还挺卷字体和卷面整洁的 不知道现在有没有什么办法可以公平比较
用户8:这个我记得已经有了吧，就是复旦那边之前就测过，选择题的
用户20:GAOKAO-Bench
用户4:好像都是 选择题之前
用户18:化学、物理里面涉及到读图的题（这些图没法转述为文字而不损失关键信息）对模型挑战挺大的，不知道国内 sota 的多模态模型到啥程度了
用户20:[让我看看] 缺的解答题，可以用 OlympiadBench 里的五三高考模拟题子集
用户20:比较经典的这道题，GPT4V能识别出是墨西哥湾流
用户18:嗯嗯，4 确实不错。但不知道国内的有没有“视力”和“脑力”都很好的了
用户11:GLM4不错的[旺柴]
用户19:贵群其实可以自发组织一下
用户19:高考的卷子一般考完当天网上就有了
用户16:感觉可能也就客观题比较有办法...占比很高的大题，比如作文（语文 & 英语），理综和数学的大题（过程中间哪步到哪步能给多少分），非事实性阅读理解（语文出这种题可能比较多，比如体会作者的感情和用意，结合（古文）的时代背景分析等等，英语这边完形填空等偏事实性的还是多一点），既不见得好打分，也不见得好做（有的时候不是model能力的问题，而是这类题可能主观性太强或者“出题人意图难以理解”）

================================================================================
chat_session_len:55
用户14:2022 年湖南卷数学选择题
用户14:GPT 4o 八个对了五个
用户1:其他模型是什么水平？
用户14:不知道啊，手动截图复制粘贴好累，贴不动了
用户11:万群，请问下，现在关于 参考音频+参考文本 翻译成 对应音色+语言的新音频，有推荐的开源项目嘛
用户4:是时候构建Gaokaoagent了
用户7:能上重本线吗（）
用户7:那上清华无望了（）
用户8:孩子得复读了
用户14:大家不要着急看我直播
用户4:hackathon题目——构建数学能考140的agent
用户14:还有五个题目，还有机会
用户14:现在做到解答题第二题了
用户14:但是这是一道几何题，我是觉得有点难的
用户4:解三角形更多是代数变换[旺柴]
用户13:嗯，我每次复现结果不稳定
用户14:算它得 3 分好了
用户13:理论上来说是不是应该做24年的高考卷比较合理
用户14:24 年不是还没出嘛
用户13:对，所以到时候和人类同步高考一下
用户13:因为我和fuyao老师居然搜到了同一套卷子给gpt4o做🤔
用户14:总共是 单选 25 / 40 + 多选 10 / 20 + 填空 0 / 20 + 大题 21 / 70 = 56 / 150
用户4:留学生zero shot这个成绩不错了[旺柴]
用户13:英语 语文应该很好？理综试试[偷笑]
用户2:还得考俩小时
用户4:不懂套路可能连中考题都做不出来
用户15:文理的数学
用户5:也许要求它用中文做成绩还会好一点
用户14:今年高考，也就是一个月之后，如果要考的话，可以给 ta in-context learning，把前五年的真题作为 in-context example
用户14:或许 open compass 的朋友会有兴趣搞一搞？ 
用户18:拉一波进群
用户4:instruction和reflection应该能改善一些成绩
用户5:我的chatgpt考场上手写python代码 好奇真有考生这么弄老师怎么判[破涕为笑]
用户14:这个题目如果是正常考生的话是得用函数的方法来比较的
用户14:但是它硬算了【 btw 一个几百 M 的模型就可以硬算常见函数的数值了
用户14:但是人肯定没办法硬算
用户5:人应该也可以泰勒硬算？
用户15:貌似不太会用最简单的方式做题
用户14:嗯，整个下来我觉得它总是倾向于使用复杂方式解题
用户14:参考答案比它简单得多
用户14:complexity based prompting 就是容易把简单问题带复杂
用户16:Actually，4o推KL的non-negativity，也是不必要的复杂化了
用户15:https://arxiv.org/pdf/2402.14008 
我们当时在OlympiadBench上做多模态和文本模型实验时，有一些有趣的发现，例如 模型选择复杂的解题过程；结论幻觉；过程引入不必要的概念等
用户14:https://x.com/liambolling/status/1792992186411430244?s=46&t=CKI7n9G54Thts9rTrC1n0Q
用户10:这么一说我想起来了，我之前在ttic学information theory的时候，我的老师好像就是jensen推的
用户17:啊我没感觉哪一步是不必要的啊
用户17:反正我感觉这个过程挺本质的，统计里面很多跟kl相关的bound也是拿p/q当随机变量的
用户3:Phi-3 Medium (14B) 发布了：https://huggingface.co/microsoft/Phi-3-medium-4k-instruct
用户4:https://arxiv.org/pdf/2301.03728
有人读过这篇关于多模态的 scaling law 的工作吗，为什么 Uni-modal 的 scaling law 力 他们说 molecules 对 scale 的利用很充分？看图似乎 molecules 的 PPL 随scale变化不大啊
用户6:各位好，受邀在国内某顶尖高校合作开大模型方面的通识课程，想给大学生们多一些接触国际最前沿的知识的机会。现在召集AI专家Guest Speaker一些AI主题（远程线上讲座即可），仿照百家讲坛形式。我们争取开百人到千人的大课。有兴趣的请私我，感谢！
用户9:gpt4 是 5x10^25 左右
用户12:其实比较好奇怎么做到无法在某些知识上被finetune
用户4:调整模型神经元模式，碰到这些知识就mode collapse，或者植入后门[脸红]
用户10:感觉这个政策的制定也挺一拍脑门的
用户10:如果我们大胆想象五年以后的算力和模型的发展，这感觉regularize不了什么...